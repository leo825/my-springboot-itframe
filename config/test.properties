

logging.config = logging-config:classpath:log4j.properties
logging.file-web=app.log
logging.file-core=core.log

spring.aop.proxy-target-class = aop-proxy-target: false
spring.aop.auto = aop-auto:false

#-- 应用服务器配置
#-- 内嵌的WEB应用服务器监听端口
server.port=port:18080
#-- 内嵌的WEB应用服务器监听地址
server.address=address:0.0.0.0
#-- 应用上下文路径
server.context-path=context-path:/edcaiom
#-- 接收新连接的队列大小最大值
server.tomcat.accept-count=accept-count:10
#-- 并发处理的最大线程数
server.tomcat.max-threads=max-threads:100
#-- 同时并发处理的最大连接数
server.tomcat.max-connections=max-conns:100
#-- tomcat base dir
server.tomcat.basedir=tmp
#-- tomcat access log配置
#-- 存放路径
server.tomcat.accesslog.directory=${user.dir}/logs
#-- 文件前缀，生成后为：前缀.日期.log
server.tomcat.accesslog.prefix=app_access_log
#-- Dubbo相关配置
#-- Dubbo服务端监听端口
dubbo.provider.port=dubbo-port:20880
#-- dubbo生产者的应用标识
dubbo.provider.application-name=dubbo-appname:edcaiom-provider
#-- dubbo生产者：默认的服务超时时间，单位：毫秒
dubbo.provider.timeout=dubbo-timeout:10000
dubbo.provider.registry-address=dubbo-zk:N/A
dubbo.provider.annotation-package = dubbo-pkg:com.cmos.edcaiom.service

#-- Dubbo服务注册与发现的zookeeper集群地址
dubbo.consumer.registry-address=dubbo-zk:zookeeper://192.168.20.159:30008?backup=192.168.20.159:30009,192.168.20.159:30010
#-- dubbo消费者的应用标识
dubbo.consumer.application-name=dubbo-appname:edcaiom-consumer
#-- dubbo消费者：对应的dubbo生产者服务地址
dubbo.consumer.reference-url=dubbo-ref:
#-- dubbo消息者：默认的服务访问超时时间，单位：毫秒
dubbo.consumer.timeout=dubbo-timeout:10000
dubbo.consumer.annotation-package = dubbo-pkg:com.cmos.edcaiom.web

#-- 远程调用HTTP连接池配置
#-- 连接池最大连接数，建议为单个tomcat最大并发的1/3~2/3
httpclient.maxTotal = 100  
#-- 连接池全局默认socket读取超时，单位为毫秒，如果存在大文件流，建议调大
httpclient.socketTimeout = 5000 

#-- 日志中心配置
#-- 日志中心开关
logger.switch.enable-control=true
logger.switch.enable-core=true
#-- 日志调试开关
logger.debug.enable-control=true
logger.debug.enable-core=true
#-- 日志级别
logger.log.level-control=info
logger.log.level-core=info
#-- 日志发送方式，部署在核心域和接口域使用kafka方式，互联网域使用file方式。
logger.msg.sender-control=kafka
logger.msg.sender-core=kafka
#-- kafka地址，根据部署环境进行选择配置
#-- 西区测试kafka集群
logger.kafka.brokerlist=192.168.100.105:9092,192.168.100.106:9092,192.168.100.107:9092
#-- 业务记录数据kafka集群
logger.userkafka.brokerlist=192.168.20.129:9092,192.168.20.133:9092,192.168.20.134:9092

#-- ONEST配置
ONEST.ENDPOINT=http://192.168.100.134
ONEST.UID=edc
ONEST.DISPLAY-NAME=edctest
ONEST.ACCESS-KEY=3WKD5JFCBFE8KB14T12F
ONEST.SECRET-KEY=BHFyFkwlb3GbZdzGdTbBcB59YHO8rlAi5wN1SXU4
ONEST.gztfile.userId=edc
ONEST.gztFile.bucketName=test-edc
ONEST.busiFile.bucketName.P=test-edc
ONEST.busiFile.bucketName.W=test-edc
ONEST.busiFile.bucketName.V=test-edc

#-- csf配置
#-- csf服务zookeeper地址，多个地址用逗号(,)隔开
csf.zkServer.list=192.168.100.144:2181
#-- 缓存中心配置
#-- redis地址
aiomcache.redisAddress=192.168.20.159:30092,192.168.20.159:30093,192.168.20.159:30094,192.168.20.195:30092,192.168.20.195:30093,192.168.20.195:30094
authcache.redisAddress=192.168.20.159:30092,192.168.20.159:30093,192.168.20.159:30094,192.168.20.195:30092,192.168.20.195:30093,192.168.20.195:30094

# 默认数据源
db.default = base

#-- 数据源配置
base.driverClassName=com.mysql.jdbc.Driver
base.url=jdbc:mysql://192.168.20.197:20001/edcaiom?useUnicode=true&characterEncoding=utf8
base.username=test5_6
base.password=rO0ABXciABCzxcc6dwm8ZV7NySEuliwtTKBh80PdmxtYohO4kg2/vA==
base.initialSize=2

# 自定义初始单
spring.app.initializers = inits:

#远程调用地址
remote.url.edcacms = http://192.168.20.100:20001/edcacms
remote.url.edccommon = http://192.168.20.100:20003/edccommon
remote.url.edcvideo = http://192.168.20.100:20011/edcvideo
remote.url.edcorder = http://192.168.20.100:20015/edcorder
remote.url.edcsms =http://192.168.20.100:20002/edcsms
remote.url.edcadapi = http://192.168.20.159:20022/edcadapi
remote.url.edcadapi.out = http://192.168.20.159:20022/edcadapi

remote.url.edcwork = http://192.168.20.159:20020/edcwork
remote.url.edcauth = http://192.168.20.159:20019/edcauth

